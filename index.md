---
layout: default
---

<ul class='menu'>
<li><a href="./">Home</a></li>
<li><a href="./CV.pdf">CV</a></li>
<li><a href="./research.html">Research</a></li>
</ul>

<p>I am currently an Assistant Professor of Information Systems at <a href="https://wpcarey.asu.edu/">Arizona State University, W. P. Carey School of Business</a>. Previously, I completed my PhD degree from University of Pennsylvania Department of Economics under the supervision of <a href="https://hamsabastani.github.io"> Hamsa Bastani</a>. I received a B.S. in Mathematics and a B.A. in Economics from Tsinghua University, and a M.S. in Statistics from University of Chicago. </p>

<p>My research focuses on developing novel machine learning methods for data-driven decision making practices, with applications to healthcare, textual analytics, digital platform, and pricing. In particular, I have designed tools for sequential decision-making (e.g., bandits, reinforcement learning), collaborative decision making (e.g., multitask learning, transfer learning), and data with unstructured (e.g. natural language processing (NLP)) or matrix form (e.g., matrix completion). </p>

<p>
I am actively looking for graduate, undergraduate students, and colleagues who might be interested in collaborating. The topics include all areas related to Information Systems, Operations Management, and Marketing, of both theoretical and applied machine learning, and empirical research. Please feel free to send me an email if you would like to chat! 
</p>

<p>
I will be presenting two works at <a href="https://ide.mit.edu/events/2023-conference-on-digital-experimentation-mit-codemit/">MIT@CODE</a>, Nov 10-11, 2023:
<ol>
<li>Session F: Bipartite Experiments, "Online Learning in Matching Market through Matrix Completion";</li>
<li>Session I: Bandits and Adaptive Experimentation, "Learning Across a Network of Bandits".</li>
</ol>
</p>